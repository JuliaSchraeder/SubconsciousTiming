{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Level Statistics with behavioural data\n",
    "  \n",
    "***\n",
    " Use the csv created in `ExtractData`\n",
    " \n",
    "  1. Descriptive  statistic\n",
    "  2. Shapiro Wilk to test normality\n",
    "  3. Homoscedasticity to test equality of variance\n",
    "  4. ANOVA to test for differences\n",
    "  5. Paired T-Test  (normal distributed data)\n",
    "  6.  Wilcoxon signed-rank test (not normal distributed data)\n",
    "***    \n",
    "- Analyse mean Reaction times (`Mean_Reactions_selected.csv`)\n",
    "- Analyse mean Accuracy (`Mean_Accuracy_selected.csv`)\n",
    "- Analyse all Reaction times (`Mean_Reactions_selected.csv` and `Reactions_all_dropna_selected.csv`)\n",
    "*** \n",
    "Theoretical Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impord modules \n",
    "import pandas as pd\n",
    "import ast, os\n",
    "import numpy as np\n",
    "import csv\n",
    "import fileinput\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import pingouin as pg\n",
    "from pingouin import ttest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Reaction times\n",
    "\n",
    "Define and execute functions to analyse  mean reaction times using the csv created in \"ExtractData\" wit mean Reactions `Mean_Reactions_selected.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reactions = pd.read_csv('C:/Users/juhoffmann/OneDrive - Uniklinik RWTH Aachen/Auswertung/Pilot2/SecondLevel/Mean_Reactions_selected.csv', sep = \";\")\n",
    "del mean_reactions['Unnamed: 0'] \n",
    "\n",
    "mean_reaction = mean_reactions['mean reaction time']\n",
    "mean_happy = mean_reactions['mean reaction time happy']\n",
    "mean_sad = mean_reactions['mean reaction time sad']\n",
    "mean_neutral = mean_reactions['mean reaction time neutral']\n",
    "mean_primer_8ms = mean_reactions['mean reaction time primer 8ms']\n",
    "mean_primer_16ms = mean_reactions['mean reaction time primer 16ms']\n",
    "mean_primer_25ms = mean_reactions['mean reaction time primer 25ms']\n",
    "mean_primer_141ms = mean_reactions['mean reaction time primer 141ms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics\n",
    "desc_stat = mean_reactions.describe()\n",
    "desc_stat = pd.DataFrame(desc_stat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normality test\n",
    "one = pg.normality(mean_reaction, alpha=.05)\n",
    "two = pg.normality(mean_happy, alpha=.05)\n",
    "three = pg.normality(mean_sad, alpha=.05)\n",
    "four = pg.normality(mean_neutral, alpha=.05)\n",
    "five = pg.normality(mean_primer_141ms, alpha=.05)\n",
    "six = pg.normality(mean_primer_25ms, alpha=.05)\n",
    "seven = pg.normality(mean_primer_16ms, alpha=.05)\n",
    "eight = pg.normality(mean_primer_8ms, alpha=.05)\n",
    "normality = pd.DataFrame(one)\n",
    "normality = normality.append(two).append(three).append(four).append(five).append(six).append(seven).append(eight)\n",
    "normality['Comparison'] = ['mean reaction',\n",
    "                                'mean happy',\n",
    "                                'mean sad',\n",
    "                                'mean neutral',\n",
    "                                'mean 141ms',\n",
    "                                'mean 25ms',\n",
    "                                'mean 16ms',\n",
    "                                'mean 8ms']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The homogeneity of variances \n",
    "homosc = pg.homoscedasticity(mean_reactions[['mean reaction time',\n",
    "                                    'mean reaction time happy',\n",
    "                                    'mean reaction time sad',\n",
    "                                    'mean reaction time neutral',\n",
    "                                    'mean reaction time primer 8ms',\n",
    "                                    'mean reaction time primer 16ms',\n",
    "                                    'mean reaction time primer 25ms',\n",
    "                                    'mean reaction time primer 141ms']],\n",
    "                    method ='bartlett') #all normal distribued\n",
    "homosc = pd.DataFrame(homosc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova = pg.rm_anova(mean_reactions)\n",
    "anova.round(3)\n",
    "\n",
    "anova = pd.DataFrame(anova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paired t test\n",
    "one = ttest(mean_happy, mean_sad, paired=True, tail='two-sided').round(4)\n",
    "two = ttest(mean_sad, mean_neutral, paired=True, tail='two-sided').round(4)\n",
    "three = ttest(mean_happy, mean_neutral, paired=True, tail='two-sided').round(4)\n",
    "\n",
    "four = ttest(mean_primer_8ms, mean_primer_141ms, tail='two-sided').round(4)\n",
    "five = ttest(mean_primer_16ms, mean_primer_141ms, tail='two-sided').round(4)\n",
    "six = ttest(mean_primer_25ms, mean_primer_141ms, tail='two-sided').round(4)  \n",
    "\n",
    "seven = ttest(mean_primer_25ms, mean_primer_8ms, tail='two-sided').round(4)\n",
    "eight = ttest(mean_primer_25ms, mean_primer_16ms, tail='two-sided').round(4)\n",
    "nine = ttest(mean_primer_8ms, mean_primer_16ms, tail='two-sided').round(4)\n",
    "\n",
    "ten = ttest(mean_reaction, mean_primer_141ms, tail='two-sided').round(4)\n",
    "eleven = ttest(mean_reaction, mean_primer_25ms, tail='two-sided').round(4)\n",
    "twelve = ttest(mean_reaction, mean_primer_16ms, tail='two-sided').round(4)\n",
    "thirteen = ttest(mean_reaction, mean_primer_8ms, tail='two-sided').round(4)\n",
    "\n",
    "fourteen = ttest(mean_reaction, mean_happy, tail='two-sided').round(4)\n",
    "fiveteen = ttest(mean_reaction, mean_sad, tail='two-sided').round(4)\n",
    "sixteen = ttest(mean_reaction, mean_neutral, tail='two-sided').round(4)\n",
    "\n",
    "Ttest = pd.DataFrame(one)\n",
    "Ttest = Ttest.append(two).append(three).append(four).append(five)\n",
    "Ttest = Ttest.append(six).append(seven).append(eight).append(nine)\n",
    "Ttest = Ttest.append(ten).append(twelve).append(twelve).append(thirteen)\n",
    "Ttest = Ttest.append(fourteen).append(fiveteen).append(sixteen)\n",
    "Ttest['Comparison'] = ['mean happy vs. mean sad',\n",
    "                                     'mean sad vs. mean neutral',\n",
    "                                     'mean happy vs. mean neutral',\n",
    "                                     'mean 8ms vs. mean 141ms',\n",
    "                                     'mean 16 ms vs. mean 141ms',\n",
    "                                     'mean 25ms vs. mean 141ms',\n",
    "                                     'mean 25ms vs. mean 8ms',\n",
    "                                     'mean 25ms vs. mean 16ms',\n",
    "                                     'mean 8ms vs. mean 16ms',\n",
    "                                     'mean reaction time vs. mean 141ms',\n",
    "                                     'mean reaction time vs. mean 25ms',\n",
    "                                     'mean reaction time vs. mean 16ms',\n",
    "                                     'mean reaction time vs. mean 8ms',\n",
    "                                     'mean reaction time vs. mean happy',\n",
    "                                     'mean reaction time vs. mean sad',\n",
    "                                  'mean reaction time vs. mean neutral']\n",
    "bon =[(0.05/3),(0.05/3),(0.05/3),(0.05/3),(0.05/3),(0.05/3),(0.05/3),(0.05/3),\n",
    "      (0.05/3),(0.05/7),(0.05/7),(0.05/7),(0.05/7),(0.05/7),(0.05/7),(0.05/7)]\n",
    "bon = [round(i, 4) for i in bon] #round values\n",
    "Ttest['Bonferroni'] = bon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wilcox test for mean accuracy  \n",
    "one = pg.wilcoxon(mean_happy, mean_sad, tail='two-sided').round(4)\n",
    "two = pg.wilcoxon(mean_happy, mean_neutral, tail='two-sided').round(4)\n",
    "\n",
    "wilcox = pd.DataFrame(one)\n",
    "wilcox = wilcox.append(two)                                                             \n",
    "\n",
    "wilcox['Comparison'] = ['mean happy vs. mean sad','mean happy vs. mean neutral']\n",
    "\n",
    "bon =[(0.05/2),(0.05/2)]\n",
    "bon = [round(i, 4) for i in bon] #round values\n",
    "wilcox['Bonferroni'] = bon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "desc_stat.to_csv(r'C:/Users/juhoffmann/OneDrive - Uniklinik RWTH Aachen/Auswertung/Pilot2/SecondLevel/Descriptive_stat_mean_Reactions_selected.csv',sep =';', index = True)\n",
    "normality.to_csv(r'C:/Users/juhoffmann/OneDrive - Uniklinik RWTH Aachen/Auswertung/Pilot2/SecondLevel/Shapiro_Test_mean_Reactions_selected.csv',sep =';', index = True)\n",
    "homosc.to_csv(r'C:/Users/juhoffmann/OneDrive - Uniklinik RWTH Aachen/Auswertung/Pilot2/SecondLevel/Homoscedasticity_mean_Reaction.csv',sep =';', index = True)\n",
    "anova.to_csv(r'C:/Users/juhoffmann/OneDrive - Uniklinik RWTH Aachen/Auswertung/Pilot2/SecondLevel/Anova_mean_Reaction.csv',sep =';', index = True)\n",
    "wilcox.to_csv(r'C:/Users/juhoffmann/OneDrive - Uniklinik RWTH Aachen/Auswertung/Pilot2/SecondLevel/Wilcox_mean_Reaction_selected.csv',sep =';', index = True)\n",
    "Ttest.to_csv(r'C:/Users/juhoffmann/OneDrive - Uniklinik RWTH Aachen/Auswertung/Pilot2/SecondLevel/Ttest_mean_Reactions_selected.csv',sep =';', index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Accuracy\n",
    "\n",
    "Define and execute functions to analyse  mean accuracy using the csv created in \"ExctractData\" wit mean Reactions `Mean_Accuracy_selected.csv`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_accuracy = pd.read_csv('C:/Users/juhoffmann/OneDrive - Uniklinik RWTH Aachen/Auswertung/Pilot2/SecondLevel/Mean_Accuracy_selected.csv', sep = \";\")\n",
    "del mean_accuracy['Unnamed: 0'] \n",
    "\n",
    "number_of_reactions = mean_accuracy['number of reactions']\n",
    "number_of_correct_answers = mean_accuracy['number of correct answers']\n",
    "accuracy = mean_accuracy['accuracy']\n",
    "accuracy_happy = mean_accuracy['accuracy happy']\n",
    "accuracy_sad = mean_accuracy['accuracy sad']\n",
    "accuracy_neutral = mean_accuracy['accuracy neutral']\n",
    "accuracy_8ms = mean_accuracy['accuracy 8ms']\n",
    "accuracy_16ms = mean_accuracy['accuracy 16ms']\n",
    "accuracy_25ms = mean_accuracy['accuracy 25ms']\n",
    "accuracy_141ms = mean_accuracy['accuracy 141ms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics\n",
    "desc_stat = mean_accuracy.describe()\n",
    "desc_stat = pd.DataFrame(desc_stat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normality Test\n",
    "zero = pg.normality(number_of_reactions, alpha=.05)\n",
    "one = pg.normality(number_of_correct_answers, alpha=.05)\n",
    "two = pg.normality(accuracy, alpha=.05)\n",
    "three = pg.normality(accuracy_happy, alpha=.05)\n",
    "four = pg.normality(accuracy_sad, alpha=.05)\n",
    "five = pg.normality(accuracy_neutral, alpha=.05)\n",
    "six = pg.normality(accuracy_8ms, alpha=.05)\n",
    "seven = pg.normality(accuracy_16ms, alpha=.05)\n",
    "eight = pg.normality(accuracy_25ms, alpha=.05)\n",
    "nine = pg.normality(accuracy_141ms, alpha=.05)\n",
    "\n",
    "normality = pd.DataFrame(zero)\n",
    "normality = normality.append(one).append(two).append(three).append(four).append(five).append(six).append(seven).append(eight).append(nine)\n",
    "normality['Comparison'] = ['number_of_reactions',\n",
    "                           'number_of_correct_answers',\n",
    "                           'accuracy',\n",
    "                           'accuracy_happy',\n",
    "                           'accuracy_sad',\n",
    "                           'accuracy_neutral',\n",
    "                           'accuracy_8ms',\n",
    "                           'accuracy_16ms',\n",
    "                           'accuracy_25ms',\n",
    "                           'accuracy_141ms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The homogeneity of variances \n",
    "homosc = pg.homoscedasticity(mean_accuracy[['number of correct answers',\n",
    "                                            'accuracy',\n",
    "                                            'accuracy happy',\n",
    "                                            'accuracy sad',\n",
    "                                            'accuracy neutral',\n",
    "                                            'accuracy 25ms']],\n",
    "                             method ='bartlett') #for normal distribued\n",
    "homosc = pd.DataFrame(homosc)\n",
    "\n",
    "homoscL = pg.homoscedasticity(mean_accuracy[['number of reactions',\n",
    "                                             'accuracy 8ms',\n",
    "                                             'accuracy 16ms',\n",
    "                                             'accuracy 141ms']],\n",
    "                              method ='levene') #for not normal distribued\n",
    "homoscL = pd.DataFrame(homoscL)\n",
    "homosc = homosc.append(homoscL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova = pg.rm_anova(mean_accuracy)\n",
    "anova.round(3)\n",
    "anova = pd.DataFrame(anova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juhoffmann\\Anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2957: UserWarning: Exact p-value calculation does not work if there are ties. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n"
     ]
    }
   ],
   "source": [
    "# Wilcox test for mean accuracy  \n",
    "# neutral and 8ms are not normal distributed\n",
    "\n",
    "one = pg.wilcoxon(accuracy_8ms, accuracy_141ms, tail='two-sided').round(4)\n",
    "two = pg.wilcoxon(accuracy_8ms, accuracy_16ms, tail='two-sided').round(4)\n",
    "three = pg.wilcoxon(accuracy_8ms, accuracy_25ms, tail='two-sided').round(4)  \n",
    "four = pg.wilcoxon(accuracy_8ms, accuracy, tail='two-sided').round(4)\n",
    "\n",
    "five = pg.wilcoxon(accuracy_neutral, accuracy_sad, tail='two-sided').round(4)\n",
    "six = pg.wilcoxon(accuracy_neutral, accuracy_happy, tail='two-sided').round(4)\n",
    "\n",
    "#= pg.wilcoxon(accuracy_8ms, accuracy_16ms, tail='two-sided').round(4)\n",
    "#\n",
    "#seven = pg.wilcoxon(accuracy_8ms, accuracy,tail='two-sided').round(4)\n",
    "#eight = pg.wilcoxon(accuracy_25ms, accuracy,tail='two-sided').round(4)\n",
    "#nine = pg.wilcoxon(accuracy_16ms, accuracy,tail='two-sided').round(4)\n",
    "#ten = pg.wilcoxon(accuracy_8ms, accuracy,tail='two-sided').round(4)\n",
    "#\n",
    "#eleven = pg.wilcoxon(accuracy_happy, accuracy,tail='two-sided').round(4)\n",
    "#twelve = pg.wilcoxon(accuracy_sad, accuracy,tail='two-sided').round(4)\n",
    "#thirteen = pg.wilcoxon(accuracy_neutral, accuracy,tail='two-sided').round(4)\n",
    "\n",
    "wilcox = pd.DataFrame(one)\n",
    "wilcox = wilcox.append(two).append(three).append(four).append(five).append(six)                                                           \n",
    "\n",
    "wilcox['Comparison'] = ['accuracy 8ms vs. accuracy 141ms',\n",
    "                        'accuracy 8ms vs. accuracy 16ms',\n",
    "                        'accuracy 8ms vs. accuracy 25ms',\n",
    "                        'accuracy 8ms vs. mean accuracy',\n",
    "                       'accuracy neutral vs. accuracy sad',\n",
    "                       'accuracy neutral vs. accuracy happy']\n",
    "\n",
    "bon =[(0.05/4),(0.05/4),(0.05/4),(0.05/4),(0.05/2),(0.05/2)]\n",
    "bon = [round(i, 4) for i in bon] #round values\n",
    "wilcox['Bonferroni'] = bon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paired T-Test for normal distributed conditions\n",
    "\n",
    "\n",
    "\n",
    "one =   ttest(accuracy_happy, accuracy_sad, paired=True, tail='two-sided').round(4)\n",
    "two =   ttest(accuracy_25ms, accuracy_16ms, tail='two-sided').round(4)\n",
    "three = ttest(accuracy_25ms, accuracy_141ms, tail='two-sided').round(4)\n",
    "four =  ttest(accuracy_16ms, accuracy_141ms, tail='two-sided').round(4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#one = ttest(accuracy_happy, accuracy_sad, paired=True, tail='two-sided').round(4)\n",
    "#two = ttest(accuracy_sad, accuracy_neutral, paired=True, tail='two-sided').round(4)\n",
    "#three = ttest(accuracy_happy, accuracy_neutral, paired=True, tail='two-sided').round(4)\n",
    "\n",
    "\n",
    "#four = ttest(accuracy_25ms, accuracy_8ms, tail='two-sided').round(4)\n",
    "#five = ttest(accuracy_25ms, accuracy_16ms, tail='two-sided').round(4)\n",
    "#six = ttest(accuracy_8ms, accuracy_16ms, tail='two-sided').round(4)\n",
    "\n",
    "#eight = ttest(accuracy_25ms, accuracy,tail='two-sided').round(4)\n",
    "#nine = ttest(accuracy_16ms, accuracy,tail='two-sided').round(4)\n",
    "#ten = ttest(accuracy_8ms, accuracy,tail='two-sided').round(4)\n",
    "\n",
    "#eleven = ttest(accuracy_happy, accuracy,tail='two-sided').round(4)\n",
    "#twelve = ttest(accuracy_sad, accuracy,tail='two-sided').round(4)\n",
    "#thirteen = ttest(accuracy_neutral, accuracy,tail='two-sided').round(4)\n",
    "\n",
    "\n",
    "Ttest = pd.DataFrame(one)\n",
    "Ttest = Ttest.append(two).append(three).append(four)\n",
    "Ttest['Comparison'] = [ 'accuracy happy vs. accuracy sad',\n",
    "                        'accuracy 25ms vs. accuracy 16ms',\n",
    "                        'accuracy 25ms vs. accuracy 141ms',\n",
    "                        'accuracy 16ms vs. accuracy 141ms']\n",
    "\n",
    "bon = [(0.05/1),(0.05/2),(0.05/2),(0.05/2)]\n",
    "bon = [round(i, 4) for i in bon] #round values                                \n",
    "Ttest['Bonferroni'] = bon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_stat.to_csv(r'C:/Users/juhoffmann/OneDrive - Uniklinik RWTH Aachen/Auswertung/Pilot2/SecondLevel/Descriptive_mean_Accuracy_selected.csv',sep =';', index = True)\n",
    "normality.to_csv(r'C:/Users/juhoffmann/OneDrive - Uniklinik RWTH Aachen/Auswertung/Pilot2/SecondLevel/Shapiro_Test_mean_Accuracy_selected.csv',sep =';', index = True)\n",
    "homosc.to_csv(r'C:/Users/juhoffmann/OneDrive - Uniklinik RWTH Aachen/Auswertung/Pilot2/SecondLevel/Homoscedasticity_mean_Accuracy_selected.csv',sep =';', index = True)\n",
    "anova.to_csv(r'C:/Users/juhoffmann/OneDrive - Uniklinik RWTH Aachen/Auswertung/Pilot2/SecondLevel/Anova_mean_Accuracy_selected.csv',sep =';', index = True)\n",
    "wilcox.to_csv(r'C:/Users/juhoffmann/OneDrive - Uniklinik RWTH Aachen/Auswertung/Pilot2/SecondLevel/Wilcox_Test_mean_Accuracy_selected.csv',sep =';', index = True)\n",
    "Ttest.to_csv(r'C:/Users/juhoffmann/OneDrive - Uniklinik RWTH Aachen/Auswertung/Pilot2/SecondLevel/Ttest_mean_Accuracy_selected.csv',sep =';', index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute Second Level Statistic for all Reaction times\n",
    "\n",
    "use previous list with all reactions created in skript \"ExtractData\" `Reactions_all_selected.csv`\n",
    "\n",
    "\n",
    "and use the same functions as above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptive_statistics(reactions_all):\n",
    "    #take everything except first column and the ID\n",
    "    participantcsv_stats = reactions_all.iloc[:,[1,2,3,4,5,6,7]] \n",
    "    # \"describe\" measures descriptive statistics\n",
    "    participant_stats = participantcsv_stats.describe() \n",
    "    #create Dataframe\n",
    "    df_stats = pd.DataFrame(participant_stats) \n",
    "\n",
    "    return df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normality for reactions in each participant\n",
    "def normality(reactions_all):\n",
    "    one = pg.normality(happy, alpha=.05)\n",
    "    two = pg.normality(sad, alpha=.05)\n",
    "    three = pg.normality(neutral, alpha=.05)\n",
    "    four = pg.normality(primer_8ms, alpha=.05)\n",
    "    five = pg.normality(primer_16ms, alpha=.05)\n",
    "    six = pg.normality(primer_25ms, alpha=.05)\n",
    "    seven = pg.normality(primer_141ms, alpha=.05)\n",
    "    eight = pg.normality(unconscious, alpha=.05)\n",
    "    #create Dataframe\n",
    "    normality_df = pd.DataFrame(one)\n",
    "    normality_list = normality_df.append(two).append(three).append(four).append(five).append(six).append(seven).append(eight)\n",
    "    normality_list['Comparison'] = ['happy',\n",
    "                                    'sad',\n",
    "                                    'neutral',\n",
    "                                    '8ms',\n",
    "                                    '16ms',\n",
    "                                    '25ms',\n",
    "                                    'conscious',\n",
    "                                    'unconscious']\n",
    "    return normality_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wilcox test for reactions in every participant\n",
    "def wilcox(reactions_all):\n",
    "    \n",
    "    #exctract values for every participant\n",
    "    happy = reactions_all['happy'].dropna()[:50]\n",
    "    sad = reactions_all['sad'].dropna()[:50]\n",
    "    neutral = reactions_all['neutral'].dropna()[:50]\n",
    "    primer_8ms = reactions_all['primer 8ms'].dropna()[:50]\n",
    "    primer_16ms = reactions_all['primer 16ms'].dropna()[:50]\n",
    "    primer_25ms = reactions_all['primer 25ms'].dropna()[:50]\n",
    "    primer_141ms = reactions_all['primer 141ms'].dropna()[:50]\n",
    "    unconscious = primer_8ms.append(primer_16ms).append(primer_25ms)[:50]\n",
    "    \n",
    "    one = pg.wilcoxon(sad, happy, tail='two-sided')\n",
    "    two = pg.wilcoxon(sad, neutral, tail='two-sided')\n",
    "    three = pg.wilcoxon(happy, neutral, tail='two-sided')\n",
    "    \n",
    "    #not the same length\n",
    "    #four = pg.wilcoxon(primer_8ms, primer_141ms, tail='two-sided')\n",
    "    #five = pg.wilcoxon(primer_16ms, primer_141ms, tail='two-sided')\n",
    "    #six = pg.wilcoxon(primer_25ms, primer_141ms, tail='two-sided')  \n",
    "    \n",
    "    seven = pg.wilcoxon(primer_25ms, primer_8ms, tail='two-sided')\n",
    "    eight = pg.wilcoxon(primer_25ms, primer_16ms, tail='two-sided')\n",
    "    nine = pg.wilcoxon(primer_8ms, primer_16ms, tail='two-sided')\n",
    "    \n",
    "    ten = pg.wilcoxon(primer_141ms, unconscious, tail='two-sided')\n",
    "    \n",
    "    wilcox_df = pd.DataFrame(one)\n",
    "    wilcox_list = wilcox_df.append(two).append(three).append(seven).append(eight).append(nine).append(ten)\n",
    "    wilcox_list['Comparison'] = ['happy vs. sad',\n",
    "                                 'sad vs. neutral',\n",
    "                                 'neutral vs. happy',\n",
    "                                 '25ms vs. 8ms',\n",
    "                                 '25ms vs. 16ms',\n",
    "                                 '8ms vs. 16ms',\n",
    "                                 'conscious vs. unconscious']\n",
    "\n",
    "    return wilcox_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reactions_all = pd.read_csv('/Users/julia/OneDrive - Uniklinik RWTH Aachen/Auswertung/Pilot2/SecondLevel/All_Reactions_selected.csv', sep = \",\") \n",
    "\n",
    "#reactions_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in csv with all reaction times \n",
    "reactions_all = pd.read_csv('C:/Users/juhoffmann/OneDrive - Uniklinik RWTH Aachen/Auswertung/Pilot2/SecondLevel/All_Reactions_selected.csv', sep = \",\") \n",
    "\n",
    "#exctract values for every participant\n",
    "happy = reactions_all['happy'].dropna()\n",
    "sad = reactions_all['sad'].dropna()\n",
    "neutral = reactions_all['neutral'].dropna()\n",
    "primer_8ms = reactions_all['primer 8ms'].dropna()\n",
    "primer_16ms = reactions_all['primer 16ms'].dropna()\n",
    "primer_25ms = reactions_all['primer 25ms'].dropna()\n",
    "primer_141ms = reactions_all['primer 141ms'].dropna()\n",
    "unconscious = primer_8ms.append(primer_16ms).append(primer_25ms)\n",
    "\n",
    "#execute function for each participant\n",
    "des_stat = descriptive_statistics(reactions_all)\n",
    "#hom_test = homoscedasticity(reactions_all)\n",
    "norm_test = normality(reactions_all)\n",
    "#wilcox_test = wilcox(reactions_all)\n",
    "\n",
    "####### Save Results #######\n",
    "\n",
    "# save one csv file for each participant\n",
    "des_stat.to_csv(r'C:/Users/juhoffmann/OneDrive - Uniklinik RWTH Aachen/Auswertung/Pilot2/SecondLevel/Descriptive_stat_all_Reactions_selected.csv',sep =';', index = True)\n",
    "#save normality test\n",
    "norm_test.to_csv(r'C:/Users/juhoffmann/OneDrive - Uniklinik RWTH Aachen/Auswertung/Pilot2/SecondLevel/Shapiro_Test_all_Reactions_selected.csv',sep =';', index = True)\n",
    "#save wilkox test for each participant\n",
    "#wilcox_test.to_csv(r'/Users/julia/OneDrive - Uniklinik RWTH Aachen/Auswertung/Pilot2/SecondLevel/Wilcox_Test_all_Reactions_selected.csv',sep =';', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The homogeneity of variances \n",
    "pg.homoscedasticity(reactions_all[['happy','sad','neutral','primer 8ms',\n",
    "                                   'primer 16ms','primer 25ms','primer 141ms']],\n",
    "                    method ='levene') #for normal distribued\n",
    "# Save\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistic for hddm suitable data\n",
    "\n",
    "use previous list with all reactions created in skript \"ExtractData\" `Reactions_all_dropna_selected.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in csv with all reaction times \n",
    "data = pd.read_csv('C:/Users/juhoffmann/OneDrive - Uniklinik RWTH Aachen/Auswertung/Pilot2/hddm/hddm_analyses_data.csv',sep =',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Kruskal Wallis Test with merged all reaction times\n",
    "from pingouin import kruskal, read_dataset\n",
    "participantcsv = pd.read_csv('C:/Users/juhoffmann/OneDrive - Uniklinik RWTH Aachen/Auswertung/Pilot2/SecondLevel/All_Reactions_dropna_selected.csv', sep = \";\") #\\t , ; \"\"\n",
    "kruskal(data=participantcsv, dv='rt', between='stim')\n",
    "kruskal(data=participantcsv, dv='rt', between='level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some theorethical background:\n",
    "***\n",
    "#### Before we calculate:  `Testing statistical premises`\n",
    "\n",
    "Statistical procedures can be classfied into either [`parametric`](https://en.wikipedia.org/wiki/Parametric_statistics) or `non parametric` prcedures, which require different necessary preconditions to be met in order to show consistent/robust results. \n",
    "Generally people assume that their data follows a gaussian distribution, which allows for parametric tests to be run.\n",
    "Nevertheless it is essential to first test the distribution of your data to decide if the assumption of normally distributed data holds, if this is not the case we would have to switch to non parametric tests.\n",
    "\n",
    "© Peer Herholz https://github.com/PeerHerholz/brainhack2020_marburg_showcases\n",
    "\n",
    "***\n",
    "#### Check Distributions\n",
    "\n",
    "data normal distrubited? test pairwise with t-test\n",
    "\n",
    "data not normal distributed? test pairwise with wolcoxon rank sum test\n",
    "\n",
    "***\n",
    "#### ANOVA\n",
    "The classic ANOVA is very powerful when the groups are normally distributed and have equal variances. However, when the groups have unequal variances, it is best to use the Welch ANOVA `(pingouin.welch_anova()` that better controls for type I error (Liu 2015). \n",
    "\n",
    "Is used to analyze the differences among means in a sample.  ANOVA provides a statistical test of whether two or more population means are equal, and therefore generalizes the t-test beyond two means.\n",
    "\n",
    "***\n",
    "#### Testing for homoscedasticity\n",
    "\n",
    "\"In statistics, a sequence or a vector of random variables is homoscedastic /ˌhoʊmoʊskəˈdæstɪk/ if all random variables in the sequence or vector have the same finite variance.\" - Wikipedia\n",
    "\n",
    "returns:\n",
    "\n",
    "equal_var : boolean True if data have equal variance.\n",
    "\n",
    "p : float P-value.\n",
    "\n",
    "Note: This function first tests if the data are normally distributed using the Shapiro-Wilk test. If yes, then the homogeneity of variances is measured using the Bartlett test. If the data are not normally distributed, the Levene test, which is less sensitive to departure from normality, is used.\n",
    "\n",
    "© Peer Herholz https://github.com/PeerHerholz/brainhack2020_marburg_showcases\n",
    "\n",
    "***\n",
    "#### Testing for normality\n",
    "\"`Shapiro Wilk normality  test`\" https://pingouin-stats.org/generated/pingouin.normality.html#pingouin.normality)\n",
    "\n",
    "Standard procedure for testing `normal distribution` tests if the `distribution` of your data `deviates significantly` from a `normal distribution`.\n",
    "The function we're using returns the following information:\n",
    "\n",
    "- W  : Test statistic\n",
    "\n",
    "- p : float\n",
    "    P-value\n",
    "\n",
    "- normal : boolean\n",
    "    True if data comes from a normal distribution.\n",
    "\n",
    "© Peer Herholz https://github.com/PeerHerholz/brainhack2020_marburg_showcases\n",
    "***\n",
    "### Non parametric tests:\n",
    "\n",
    "\n",
    "Unlike the parametric test these do not require the assumption of normal distributions.\n",
    "\n",
    "\"`Mann-Whitney U Test`\" (= Wilcoxon rank-sum test). It is the non-parametric version of the independent T-test.\n",
    "Mwu tests the hypothesis that data in x and y are samples from continuous distributions with equal medians. The test assumes that x and y are independent. This test corrects for ties and by default uses a continuity correction.\" - [mwu-function](https://pingouin-stats.org/generated/pingouin.mwu.html#pingouin.mwu)\n",
    "\n",
    "Test summary\n",
    "\n",
    "- 'W-val' : W-value\n",
    "- 'p-val' : p-value\n",
    "- 'RBC'   : matched pairs rank-biserial correlation (effect size)\n",
    "- 'CLES'  : common language effect size\n",
    "    \n",
    "© Peer Herholz https://github.com/PeerHerholz/brainhack2020_marburg_showcases\n",
    "***\n",
    "#### Wilcoxon signed-rank test\n",
    "\n",
    "\"`Wilcoxon signed-rank test`\" is the non-parametric version of the paired T-test.\n",
    "\n",
    "The Wilcoxon signed-rank test tests the null hypothesis that two related paired samples come from the same distribution. A continuity correction is applied by default.\" - [wilcoxon - func](https://pingouin-stats.org/generated/pingouin.wilcoxon.html#pingouin.wilcoxon)\n",
    "Note that a listwise deletion of missing values is automatically applied.\n",
    "\n",
    "***\n",
    "#### Kruskal-Wallis\n",
    "`The Kruskal-Wallis H-test` tests the null hypothesis that the population median of all of the groups are equal. It is a non-parametric version of ANOVA. The test works on 2 or more independent samples, which may have different sizes.\n",
    "Due to the assumption that H has a chi square distribution, the number of samples in each group must not be too small. A typical rule is that each sample must have at least 5 measurements.\n",
    "\n",
    "NaN values are automatically removed.\n",
    "\n",
    "\n",
    "***\n",
    "### Parametric tests:\n",
    "`paired T-Test`tests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pilot_Analysis_UK",
   "language": "python",
   "name": "pilot_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
